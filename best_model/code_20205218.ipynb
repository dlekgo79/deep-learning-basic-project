{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a7d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "for i in tqdm(range(1000)):\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b86cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ef8d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataframe = pd.read_csv('C:/deep_basic/2023-final/data.csv')#train data 블러오기\n",
    "test_df = pd.read_csv('C:/deep_basic/2023-final/testdata.csv')#test data 불러오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f204c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df = train_test_split(train_dataframe, shuffle=True, test_size=0.15, stratify=train_dataframe['Label'])\n",
    "#train과 validation set 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c218d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# custom dataset\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, train='train', transform=None):\n",
    "        if train == 'train':# train의 경우\n",
    "            self.image_list = []#image list 생성\n",
    "            self.label_list = []#label list 생성\n",
    "            self.other_list = []#인종 나이 성별 리스트 생성\n",
    "            path = 'C:/deep_basic/2023-final/dataset/{}/{}'\n",
    "            for index, row in dataframe.iterrows():\n",
    "                image_path = row['Image'] #데이터 path 를 불러오기\n",
    "                image_label = row['Label']#데이터 path 불러오기\n",
    "                image_age = row['Age']#나이 path\n",
    "                image_gender = row['Gender']#성별 path\n",
    "                image_race = row['Race']#나이 path\n",
    "                image = Image.open(path.format(image_label, image_path)).convert('RGB')#경로를 통해서 이미지 가지고 오기\n",
    "                # if there is transform, apply transform\n",
    "                if transform != None:\n",
    "                    image = transform(image)\n",
    "                self.image_list.append(image)#만들어 놓은 리스트에 추가\n",
    "                self.label_list.append(image_label)#만들어 놓은 리스트에 추가\n",
    "                self.other_list.append((image_age, image_gender, image_race))#만들어 놓은 리스트에 추가\n",
    "\n",
    "        elif train == 'test':#test의 경우\n",
    "            self.image_list = []\n",
    "            self.label_list = []  # 이미지의 경로\n",
    "            self.other_list = []\n",
    "            path = 'C:/deep_basic/2023-final/testset/{}'\n",
    "            for index, row in dataframe.iterrows():\n",
    "                image_path = row['Image']\n",
    "                image_gender = row['Gender']\n",
    "                image_race = row['Race']\n",
    "                image = Image.open(path.format(image_path)).convert('RGB')\n",
    "                if transform != None:\n",
    "                    image = transform(image)\n",
    "                self.image_list.append(image)\n",
    "                self.label_list.append(image_path)\n",
    "                self.other_list.append((image_gender, image_race))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.image_list[idx], self.label_list[idx], self.other_list[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaf0ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from autoaugment import *\n",
    "\n",
    "train_transform = transforms.Compose([#train transform\n",
    "\n",
    "    transforms.RandomHorizontalFlip(),# train 이미지 좌우 반전\n",
    "    transforms.Resize(224),# train 이미지 크기 변경\n",
    "    transforms.ToTensor(),# train 이미지 ToTensor()로 변환해서 학습 할 수 있게!\n",
    "    transforms.Normalize([0.602927 ,0.46158618 ,0.39498535], [0.21958497, 0.19605462 ,0.18665607])# train 이미지의 평균과 표준 편차로 나누어 정규화 하는 것\n",
    "\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([#test transform\n",
    "    transforms.Resize(224),#test 이미지 크기 변경\n",
    "    transforms.ToTensor(),#test 이미지 ToTensor()로 변경\n",
    "    transforms.Normalize([0.602927 ,0.46158618, 0.39498535],[0.21958497 ,0.19605462, 0.18665607])#test 이미지 평균과 표준 편차로 나누어 정규화\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(train_df, train='train', transform=train_transform)\n",
    "valid_dataset = CustomDataset(valid_df, train='train', transform=test_transform)\n",
    "test_dataset = CustomDataset(test_df, train='test', transform=test_transform)\n",
    "\n",
    "# dataset에 대한 data loaders 구성\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# normalize를 위해 rgb 채널의 mean, std 값 구하기\n",
    "\n",
    "images,labels,other = next(iter(train_loader))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d16442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meanRGB = [np.mean(x.numpy(), axis=(2,3)) for x,label,other in train_loader]\n",
    "# stdRGB = [np.std(x.numpy(), axis=(2,3)) for x,label,other in train_loader]\n",
    "#\n",
    "# meanR = np.mean([m[0] for m in meanRGB])\n",
    "# meanG = np.mean([m[1] for m in meanRGB])\n",
    "# meanB = np.mean([m[2] for m in meanRGB])\n",
    "#\n",
    "# stdR = np.mean([s[0] for s in stdRGB])\n",
    "# stdG = np.mean([s[1] for s in stdRGB])\n",
    "# stdB = np.mean([s[2] for s in stdRGB])\n",
    "#\n",
    "# print(meanR, meanG, meanB)\n",
    "# print(stdR, stdG, stdB)\n",
    "# # RGB별로 평균,표준 편차\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ba525",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# define the CNN architecture\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # convolutional layer (sees 3x224x224) -> 이미지를 resize 했으므로 224 x 224 x 3(channel)\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=(1, 1))# 1층의 CONV2d은 in_channel이 3 output_channel이 16 padding은 1 stride 1 kernel 3\n",
    "        self.bn1 = nn.BatchNorm2d(16) # 1층의 Batchnorm은 out_channel의 크기 16\n",
    "        self.relu1 = nn.ReLU(True)#activation function은 relu\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)#Maxpool을 통해서 이미지의 크기를 절반으로 줄임\n",
    "\n",
    "        # convolutional layer (sees 16x112x112)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=(1, 1))# 2층의 CONV2d은 in_channel이 16 output_channel이 32 padding은 1 stride 1 kernel 3\n",
    "        self.bn2 = nn.BatchNorm2d(32)# 2층의 Batchnorm은 out_channel의 크기 32\n",
    "        self.relu2 = nn.ReLU(True)#activation function은 relu\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)#Maxpool을 통해서 이미지의 크기를 절반으로 줄임\n",
    "\n",
    "        # convolutional layer (sees 32x56x56)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, padding=(1, 1))#3층의 CONV2d은 in_channel이 32 output_channel이 32 padding은 1 stride 1 kernel 3\n",
    "        self.bn3 = nn.BatchNorm2d(32)# 3층의 Batchnorm은 out_channel의 크기 32\n",
    "        self.relu3 = nn.ReLU(True)#activation function은 relu\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)#Maxpool을 통해서 이미지의 크기를 절반으로 줄임\n",
    "\n",
    "        # convolutional layer (sees 32x28x28)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3, padding=(1, 1))#4층의 CONV2d은 in_channel이 32 output_channel이 64 padding은 1 stride 1 kernel 3\n",
    "        self.bn4 = nn.BatchNorm2d(64)# 4층의 Batchnorm은 out_channel의 크기 64\n",
    "        self.relu4 = nn.ReLU(True)#activation function은 relu\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)#Maxpool을 통해서 이미지의 크기를 절반으로 줄임\n",
    "\n",
    "        # 64x 14x14\n",
    "        self.conv5 = nn.Conv2d(64,64, 3, padding=(1, 1))#5층의 CONV2d은 in_channel이 64 output_channel이 64 padding은 1 stride 1 kernel 3\n",
    "        self.bn5 = nn.BatchNorm2d(64)# 5층의 Batchnorm은 out_channel의 크기 64\n",
    "        self.relu5 = nn.ReLU(True)#activation function은 relu\n",
    "        self.pool5 = nn.MaxPool2d(2, 2)#Maxpool을 통해서 이미지의 크기를 절반으로 줄임\n",
    "\n",
    "        # 64x7x7\n",
    "        self.conv6 = nn.Conv2d(64,128, 3, padding=(1, 1))#6층의 CONV2d은 in_channel이 64 output_channel이 64 padding은 1 stride 1 kernel 3\n",
    "        self.bn6 = nn.BatchNorm2d(128)# 6층의 Batchnorm은 out_channel의 크기 64\n",
    "        self.relu6 = nn.ReLU(True)#activation function은 relu\n",
    "        #특성 추출 끝\n",
    "\n",
    "        #분류 시작\n",
    "        # 128x7x7\n",
    "        self.dropout7 = nn.Dropout(0.3)#뉴런을 무작위로 0.3 만큼 삭제하고 학습\n",
    "        self.fc1 = nn.Linear(6272+2, 500)#conv6층에서 128 x 7 x 7 = 6272 그리고 인종 나이 특성 2개 추가\n",
    "        self.bcfc1 = nn.BatchNorm1d(500)#Flatten 해서 1차원이 되어서 BatchNorm1d로 fc1의 out_channel 500이 입력으로\n",
    "        self.relu7 = nn.ReLU(True)#activation function Relu\n",
    "        # linear layer (500 -> 5)\n",
    "        self.dropout8 = nn.Dropout(0.3)#뉴런을 무작위로 0.3 만큼 삭제하고 학습\n",
    "        self.fc2 = nn.Linear(500, 5)#총 5 label로 분류를 해야하므로 out은 5\n",
    "\n",
    "        self.initialize_weights()#가중치 초기화\n",
    "\n",
    "    def initialize_weights(self):#각 layer 별로 가중치 초기화 -> Relu에 맞는 가중치 초기화 적용\n",
    "        torch.nn.init.kaiming_uniform_(self.conv1.weight.data)\n",
    "        torch.nn.init.kaiming_uniform_(self.conv2.weight.data)\n",
    "        torch.nn.init.kaiming_uniform_(self.conv3.weight.data)\n",
    "        torch.nn.init.kaiming_uniform_(self.conv4.weight.data)\n",
    "        torch.nn.init.kaiming_uniform_(self.conv5.weight.data)\n",
    "        torch.nn.init.kaiming_uniform_(self.conv6.weight.data)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc1.weight.data)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc2.weight.data)\n",
    "\n",
    "\n",
    "    def forward(self, x, data1, data2):\n",
    "        # add sequence of convolutional and max pooling layers #위의 구조와 같이 모델을 쌓아주었다.\n",
    "        x = self.conv1(x)#conv2d()\n",
    "        x = self.bn1(x)#batchnorm\n",
    "        x = self.relu1(x)#activation funcrion\n",
    "        x = self.pool1(x)#maxpooling\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.pool5(x)\n",
    "\n",
    "\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.relu6(x)\n",
    "\n",
    "\n",
    "        x = x.view(-1,6272) #flatten을 해서 1차원으로 만들어서 분류하기 위해\n",
    "\n",
    "        #특성 2개를 reshape를 통해서 batch_size 만큼의 열 뒤에 2개 씩 추가\n",
    "        data1 = data1.reshape(-1, 1)#나이\n",
    "        data2 = data1.reshape(-1, 1)#인종\n",
    "        #열 뒤에 특성 2개를  합치기 위한 코드\n",
    "        x = torch.cat((x, data1), dim=1)\n",
    "        x = torch.cat((x, data2), dim=1)\n",
    "\n",
    "        x = self.dropout7(x)\n",
    "        x = self.relu7(self.bcfc1(self.fc1(x)))\n",
    "        x = self.dropout8(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb934906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a complete CNN\n",
    "model = ConvNet()\n",
    "print(model)\n",
    "# move tensors to GPU if CUDA is available\n",
    "model.to(device)\n",
    "\n",
    "# create a complete CNN\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "\n",
    "# cost 함수 및 optim 설정\n",
    "import torch.optim as optim\n",
    "\n",
    "#label smoothing\n",
    "\n",
    "nSamples = [1039,1032,1023,1023,1021]#각 클래스의 이미지의 개수\n",
    "normedWeights = [1-(x/sum(nSamples)) for x in nSamples]#평균으로 나누어 정규화한 가중치 저장\n",
    "normedWeights = torch.FloatTensor(normedWeights).to(device)#정규화된 가중치 뱐환\n",
    "normedWeights = normedWeights/5\n",
    "print(normedWeights)\n",
    "weights = torch.FloatTensor([0.1596, 0.1598, 0.1602, 0.1602, 0.1603]).cuda()#가중치 값을 GPU로 올리기\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight =weights,label_smoothing=0.01)#label_smoothing을 통해 정도를 넣어줌\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=0.05)  #optimizer\n",
    "\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=10,eta_min=0)#스케줄러\n",
    "#\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
    "\n",
    "# Train and validation\n",
    "# number of epochs to train the model\n",
    "n_epochs = 50  # 65번은 오버피팅이 남\n",
    "\n",
    "valid_loss_min = np.Inf  # track change in validation loss\n",
    "\n",
    "# keep track of training and validation loss\n",
    "train_loss = torch.zeros(n_epochs)#각 loss들 초기화\n",
    "valid_loss = torch.zeros(n_epochs)\n",
    "\n",
    "train_acc = torch.zeros(n_epochs)\n",
    "\n",
    "valid_acc = torch.zeros(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e57de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for e in range(0, n_epochs):#학습 시작\n",
    "\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()#train 시작\n",
    "    # Image,Label,Age,Gender,Race\n",
    "    for images, labels, other in train_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        images, labels, other1, other2 = images.to(device), labels.to(device), other[1].to(device), other[2].to(device)\n",
    "\n",
    "        # clear the gradients of all optimized variables\n",
    "\n",
    "        optimizer.zero_grad() #모든 gradient를 초기화\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        logits = model(images, other1, other2) #확률값 -> forward\n",
    "        # calculate the batch loss\n",
    "\n",
    "\n",
    "        loss = criterion(logits, labels)#위에서 구한 예측값을 넣어서 예측\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward() #backpropagation 과정\n",
    "        optimizer.step()\n",
    "\n",
    "        # perform a single optimization step (parameter update)\n",
    "#\n",
    "        # update training loss\n",
    "        #train_loss[e] += loss.item()\n",
    "        train_loss[e] += loss.detach().cpu().item()\n",
    "\n",
    "\n",
    "        ps = F.softmax(logits, dim=1)#확률로 변환\n",
    "        top_p, top_class = ps.topk(1, dim=1)#가장 확률이 높은 레이블\n",
    "        equals = top_class == labels.reshape(top_class.shape)\n",
    "        train_acc[e] += torch.mean(equals.type(torch.float)).detach().cpu()\n",
    "\n",
    "    scheduler.step()#스케줄러를 update -> 정한 epoch마다\n",
    "    train_loss[e] /= len(train_loader)\n",
    "    train_acc[e] /= len(train_loader)\n",
    "    # scheduler.step(train_loss[e])\n",
    "    ######################\n",
    "    # validate the model #\n",
    "    ######################\n",
    "    with torch.no_grad():\n",
    "        model.eval() #검증\n",
    "        for images, labels, other in valid_loader:\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            images, labels, other1, other2 = images.to(device), labels.to(device), other[1].to(device), other[2].to(device)\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            logits = model(images, other1, other2)#validation data를 예측\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(logits, labels)#정답값과 비교\n",
    "            # update average validation loss\n",
    "            valid_loss[e] += loss.item()\n",
    "\n",
    "            ps = F.softmax(logits, dim=1)#이 예측값을 확률값으로\n",
    "            top_p, top_class = ps.topk(1, dim=1)#가장 높은 레이블\n",
    "            equals = top_class == labels.reshape(top_class.shape)\n",
    "            valid_acc[e] += torch.mean(equals.type(torch.float)).detach().cpu()\n",
    "\n",
    "    # calculate average losses\n",
    "    # scheduler.step(valid_loss[e])\n",
    "    valid_loss[e] /= len(valid_loader)\n",
    "    valid_acc[e] /= len(valid_loader)\n",
    "\n",
    "\n",
    "    # print training/validation statistics\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        e, train_loss[e], valid_loss[e]))\n",
    "\n",
    "    # print training/validation statistics\n",
    "    print('Epoch: {} \\tTraining accuracy: {:.6f} \\tValidation accuracy: {:.6f}'.format(\n",
    "        e, train_acc[e], valid_acc[e]))\n",
    "\n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss[e] <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} '\n",
    "              '--> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss[e]))\n",
    "        # torch.save(model.state_dict(), 'convet_best3_6_19_11_48_1_MODEL.pt')\n",
    "        valid_loss_min = valid_loss[e]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LOSS 그래프\n",
    "# model.load_state_dict(torch.load('convet_best3_6_19_11_48_1_MODEL.pt'))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loss graph\n",
    "plt.plot(train_loss, label='training loss')\n",
    "plt.plot(valid_loss, label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# accuracy graph\n",
    "plt.plot(train_acc, label = 'training accuracy')\n",
    "plt.plot(valid_acc, label = 'validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# test loss\n",
    "\n",
    "id_list = []\n",
    "pred_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for images, file_name, other in test_loader:\n",
    "        images = images.to(device)\n",
    "\n",
    "        other1 = other[0].to(device)\n",
    "        other2 = other[1].to(device)\n",
    "        logits = model(images, other1, other2)\n",
    "\n",
    "        ps = F.softmax(logits, dim=1)\n",
    "\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "\n",
    "        id_list += list(file_name)\n",
    "        pred_list += top_class.T.tolist()[0]\n",
    "\n",
    "# handout_result = pd.DataFrame({'Id': id_list, 'Category': pred_list})\n",
    "# handout_result.to_csv('./result_BEST3_MODEL_6_19_11_48_1.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "#matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "classes = ['1~10', '11~20', '21~30', '31~40', '41~']\n",
    "classes_cm = [0, 1, 2, 3, 4]\n",
    "test_loss = 0\n",
    "y_pred = []\n",
    "y_true = []\n",
    "test_acc = 0\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for data, labels, other in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        data, labels, other1, other2 = data.to(device), labels.to(device), other[1].to(device), other[2].to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        logits = model(data, other1, other2)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(logits, labels)\n",
    "        # update average test loss\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        top_p, top_class = logits.topk(1, dim=1)\n",
    "        y_pred.extend(top_class.data.cpu().numpy())\n",
    "        y_true.extend(labels.data.cpu().numpy())\n",
    "        equals = top_class == labels.reshape(top_class.shape)\n",
    "        test_acc += torch.sum(equals.type(torch.float)).detach().cpu()\n",
    "\n",
    "    test_acc /= len(valid_loader.dataset)\n",
    "    test_acc *= 100\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=classes_cm, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "print('Test accuracy : {}'.format(test_acc))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
